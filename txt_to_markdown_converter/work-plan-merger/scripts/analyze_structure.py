#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å·¥ä½œè§„åˆ’ç»“æ„åˆ†æå·¥å…·
è§£ææ€»çº²æ–‡æ¡£çš„ç« èŠ‚ç»“æ„å’Œä¸»é¢˜åˆ†å¸ƒ
"""

import argparse
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple


class PlanAnalyzer:
    def __init__(self):
        self.heading_pattern = re.compile(r'^(#{1,6})\s+(.+)$', re.MULTILINE)

    def analyze_structure(self, file_path: str) -> Dict:
        """åˆ†æmarkdownæ–‡ä»¶çš„ç»“æ„"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–æ ‡é¢˜ç»“æ„
        headings = self._extract_headings(content)

        # åˆ†æä¸»é¢˜åˆ†å¸ƒ
        themes = self._analyze_themes(content, headings)

        # ç”Ÿæˆç»“æ„æŠ¥å‘Š
        structure = {
            'file_path': file_path,
            'total_headings': len(headings),
            'heading_levels': self._count_levels(headings),
            'main_sections': [h for h in headings if h['level'] <= 2],
            'detailed_structure': headings,
            'themes': themes
        }

        return structure

    def _extract_headings(self, content: str) -> List[Dict]:
        """æå–æ‰€æœ‰æ ‡é¢˜åŠå…¶ä½ç½®"""
        headings = []
        lines = content.split('\n')

        for i, line in enumerate(lines):
            match = self.heading_pattern.match(line)
            if match:
                level = len(match.group(1))
                title = match.group(2).strip()
                headings.append({
                    'level': level,
                    'title': title,
                    'line_number': i + 1,
                    'content_preview': self._get_content_preview(content, i)
                })

        return headings

    def _get_content_preview(self, content: str, heading_line: int) -> str:
        """è·å–æ ‡é¢˜åçš„å†…å®¹é¢„è§ˆ"""
        lines = content.split('\n')
        start = heading_line
        end = min(start + 5, len(lines))

        preview_lines = []
        for i in range(start + 1, end):
            if lines[i].startswith('#'):
                break
            preview_lines.append(lines[i])

        preview = ' '.join(preview_lines).strip()
        return preview[:100] + '...' if len(preview) > 100 else preview

    def _analyze_themes(self, content: str, headings: List[Dict]) -> List[Dict]:
        """åˆ†ææ–‡æ¡£ä¸»é¢˜"""
        themes = []

        # åŸºäºä¸€çº§å’ŒäºŒçº§æ ‡é¢˜è¯†åˆ«ä¸»è¦ä¸»é¢˜
        main_headings = [h for h in headings if h['level'] <= 2]

        for heading in main_headings:
            theme_keywords = self._extract_keywords(heading['title'] + ' ' + heading['content_preview'])
            themes.append({
                'title': heading['title'],
                'level': heading['level'],
                'keywords': theme_keywords,
                'line_number': heading['line_number']
            })

        return themes

    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–é€»è¾‘
        common_words = {'çš„', 'å’Œ', 'åœ¨', 'æ˜¯', 'ä¸º', 'äº†', 'ä¸', 'ä¸­', 'æœ‰', 'åŠ', 'ç­‰', 'æˆ–', 'å°†', 'ä¼š', 'å¯¹', 'è¿›è¡Œ'}
        words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', text.lower())
        keywords = [word for word in words if len(word) > 1 and word not in common_words]
        return list(set(keywords))[:10]  # è¿”å›å‰10ä¸ªç‹¬ç‰¹å…³é”®è¯

    def _count_levels(self, headings: List[Dict]) -> Dict[int, int]:
        """ç»Ÿè®¡å„çº§æ ‡é¢˜æ•°é‡"""
        levels = {}
        for heading in headings:
            level = heading['level']
            levels[level] = levels.get(level, 0) + 1
        return levels


def main():
    parser = argparse.ArgumentParser(description='åˆ†æå·¥ä½œè§„åˆ’æ–‡æ¡£ç»“æ„')
    parser.add_argument('file_path', help='è¦åˆ†æçš„markdownæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºåˆ†æç»“æœåˆ°æ–‡ä»¶')
    parser.add_argument('--format', choices=['json', 'text'], default='text', help='è¾“å‡ºæ ¼å¼')

    args = parser.parse_args()

    analyzer = PlanAnalyzer()
    structure = analyzer.analyze_structure(args.file_path)

    if args.format == 'json':
        output = json.dumps(structure, ensure_ascii=False, indent=2)
    else:
        output = format_structure_as_text(structure)

    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(output)
        print(f"ç»“æ„åˆ†æç»“æœå·²ä¿å­˜åˆ°: {args.output}")
    else:
        print(output)


def format_structure_as_text(structure: Dict) -> str:
    """å°†ç»“æ„åˆ†æç»“æœæ ¼å¼åŒ–ä¸ºæ–‡æœ¬"""
    output = []
    output.append("=" * 50)
    output.append(f"æ–‡æ¡£ç»“æ„åˆ†æ: {structure['file_path']}")
    output.append("=" * 50)
    output.append("")

    # åŸºæœ¬ä¿¡æ¯
    output.append("ğŸ“Š åŸºæœ¬ä¿¡æ¯:")
    output.append(f"  æ€»æ ‡é¢˜æ•°: {structure['total_headings']}")
    output.append(f"  ä¸»è¦ç« èŠ‚æ•°: {len(structure['main_sections'])}")
    output.append("")

    # æ ‡é¢˜å±‚çº§åˆ†å¸ƒ
    output.append("ğŸ“ˆ æ ‡é¢˜å±‚çº§åˆ†å¸ƒ:")
    for level, count in sorted(structure['heading_levels'].items()):
        prefix = "#" * level
        output.append(f"  {prefix} çº§æ ‡é¢˜: {count} ä¸ª")
    output.append("")

    # ä¸»è¦ç« èŠ‚
    output.append("ğŸ“‹ ä¸»è¦ç« èŠ‚:")
    for section in structure['main_sections']:
        prefix = "#" * section['level']
        preview = section['content_preview'][:50]
        output.append(f"  {prefix} {section['title']}")
        if preview:
            output.append(f"    é¢„è§ˆ: {preview}...")
    output.append("")

    # ä¸»é¢˜åˆ†æ
    output.append("ğŸ·ï¸ ä¸»é¢˜åˆ†æ:")
    for theme in structure['themes']:
        prefix = "#" * theme['level']
        keywords = ", ".join(theme['keywords'][:5])
        output.append(f"  {prefix} {theme['title']}")
        output.append(f"    å…³é”®è¯: {keywords}")

    return "\n".join(output)


if __name__ == "__main__":
    main()